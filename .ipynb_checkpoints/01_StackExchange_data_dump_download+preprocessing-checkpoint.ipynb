{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#downloading data imports\n",
    "from __future__ import print_function, division\n",
    "import requests\n",
    "import re\n",
    "import wget\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xmltodict\n",
    "import warnings\n",
    "import itertools\n",
    "from bs4 import BeautifulSoup\n",
    "warnings.filterwarnings('ignore')\n",
    "#LSTM model imports\n",
    "import os\n",
    "import nltk\n",
    "import gensim\n",
    "from gensim import corpora, models, similarities\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize, WhitespaceTokenizer\n",
    "import pickle\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_urls(site, keyword_string):\n",
    "    soup = to_soup(site)\n",
    "    hrefs = soup.find_all('a', class_=re.compile(keyword_string))\n",
    "    links = []\n",
    "    for anchor in hrefs:\n",
    "        links.append(anchor['href'])\n",
    "    links = ['https://archive.org' + x for x in links]\n",
    "    return links\n",
    "\n",
    "def to_soup(url):\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    return soup\n",
    "def postsxmltodf(path):\n",
    "    questionlist = []\n",
    "    answerlist = []\n",
    "    with open(path) as fd:\n",
    "        \n",
    "        doc = xmltodict.parse(fd.read())\n",
    "        docref = doc['posts']['row']\n",
    "        for i in range(len(docref)):\n",
    "            PostTypeId = BeautifulSoup(docref[i]['@PostTypeId']).text\n",
    "            body = BeautifulSoup(docref[i]['@Body']).text\n",
    "            ID = BeautifulSoup(docref[i]['@Id']).text\n",
    "            if PostTypeId == '1':\n",
    "                title = BeautifulSoup(docref[i]['@Title']).text\n",
    "                questionlist.append((ID,PostTypeId,title,body))\n",
    "            elif PostTypeId == '2':\n",
    "                parentID = BeautifulSoup(docref[i]['@ParentId']).text\n",
    "                answerlist.append((ID,PostTypeId,parentID,body))\n",
    "    qdf = pd.DataFrame(questionlist, columns=['ID','PostTypeID', 'Title', 'Body'])\n",
    "    adf = pd.DataFrame(answerlist, columns=['ID','PostTypeID', 'parentID', 'Body'])\n",
    "    return qdf, adf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Download Links and Retrieving Data\n",
    "\n",
    "#### Script to download individual data dump files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'https://archive.org/details/stackexchange'\n",
    "\n",
    "urllist = list(get_urls(url, 'stealth download-pill'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://archive.org/download/stackexchange/3dprinting.stackexchange.com.7z',\n",
       " 'https://archive.org/download/stackexchange/academia.stackexchange.com.7z',\n",
       " 'https://archive.org/download/stackexchange/ai.stackexchange.com.7z',\n",
       " 'https://archive.org/download/stackexchange/android.stackexchange.com.7z',\n",
       " 'https://archive.org/download/stackexchange/anime.stackexchange.com.7z',\n",
       " 'https://archive.org/download/stackexchange/apple.stackexchange.com.7z',\n",
       " 'https://archive.org/download/stackexchange/arabic.stackexchange.com.7z',\n",
       " 'https://archive.org/download/stackexchange/arduino.stackexchange.com.7z',\n",
       " 'https://archive.org/download/stackexchange/askubuntu.com.7z',\n",
       " 'https://archive.org/download/stackexchange/astronomy.stackexchange.com.7z']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllist[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "searchterm = 'lifehack'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://archive.org/download/stackexchange/lifehacks.stackexchange.com.7z']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_link = [x for x in urllist if searchterm in x and 'meta' not in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wget.download(my_link[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download all data dump files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "non_meta_dl_links = [x for x in urllist if 'meta' not in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in urllist[urllist.URL.str.contains(\"meta\") == False]['URL']:\n",
    "    wget.download(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Processing of downloaded xml file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import xml download directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lifehacks = '~/lifehacks.stackexchange.com/Posts.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q_lh_df, a_lh_df = postsxmltodf(lifehacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q_lh_df.columns = ['ID_q', 'PostTypeID_q', 'Title', 'Body']\n",
    "a_lh_df.columns = ['ID_a', 'PostTypeID_a', 'parentqID', 'Body']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2vec import and preprocessing\n",
    "\n",
    "* Using Google word2vec for encoding word vectors\n",
    "\n",
    "* Into 2 lists of questions and answers to attempt an implementation of a Keras LSTM model by https://github.com/shreyans29/ available here: https://github.com/shreyans29/thesemicolon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/RGD/Downloads/\")\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q2df = q_lh_df.set_index('ID_q').drop('Body', axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matcheddf = a_lh_df.join(q2df, on='parentqID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qlist = matcheddf.set_index('parentqID').iloc[:,4].tolist()\n",
    "alist = matcheddf.set_index('parentqID').iloc[:,2].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6226 6226\n"
     ]
    }
   ],
   "source": [
    "print(len(qlist),len(alist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alistclean = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in alist:\n",
    "    alistclean.append(''.join(list(filter(None, i.split('\\n')))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tok_q = []\n",
    "tok_a = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(qlist)):\n",
    "    tok_q.append(nltk.word_tokenize(qlist[i].lower()))\n",
    "    tok_a.append(nltk.word_tokenize(alistclean[i].lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec_x=[]\n",
    "for sent in tok_q:\n",
    "    sentvec = [model[w] for w in sent if w in model.vocab]\n",
    "    vec_x.append(sentvec)\n",
    "    \n",
    "vec_y=[]\n",
    "for sent in tok_a:\n",
    "    sentvec = [model[w] for w in sent if w in model.vocab]\n",
    "    vec_y.append(sentvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentend=np.ones((300,),dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for tok_sent in vec_x:\n",
    "    tok_sent[14:]=[]\n",
    "    tok_sent.append(sentend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for tok_sent in vec_x:\n",
    "    if len(tok_sent)<15:\n",
    "        for i in range(15-len(tok_sent)):\n",
    "            tok_sent.append(sentend) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for tok_sent in vec_y:\n",
    "    tok_sent[14:]=[]\n",
    "    tok_sent.append(sentend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for tok_sent in vec_y:\n",
    "    if len(tok_sent)<15:\n",
    "        for i in range(15-len(tok_sent)):\n",
    "            tok_sent.append(sentend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('conversation.pickle','wb') as f:\n",
    "    pickle.dump([vec_x,vec_y],f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing questions and answers to a txt file as alternating pairs for TensorFlow seq2seq wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = [None]*(len(qlist)+len(alist))\n",
    "result[::2] = qlist\n",
    "result[1::2] = alistclean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('lifehacks.txt', 'w') as wr:\n",
    "    for i in result:\n",
    "        wr.write(i+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How can I safely trim my fingernails without a fingernail clipper?',\n",
       " \"As you pointed out, a knife is not a good idea. You can use a standard pair of scissors safely though.\\nIf you don't have that, then (as much as I hate to say such a thing) bite them.\\n\",\n",
       " 'How can I clean my sticky keyboard?']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
